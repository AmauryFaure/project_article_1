{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitbaseconda67962706fddd4eb99e2936a1eb425e21",
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Utiliser Ray-Serve pour \"Servir\" le modèle Camembert :\n",
    "\n",
    "Ce Notebook explore l'utilisation de Ray-Serve pour pouvoir créer une API et ainsi pouvoir appeler le modèle Camembert depuis n'importe où. Notamment depuis le site web INSPIRE. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Librairies\n",
    "from transformers import CamembertForSequenceClassification,CamembertTokenizer, Trainer\n",
    "import ray\n",
    "from ray import serve\n",
    "import requests\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Initilization d'arguments :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=argparse.Namespace()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "#Use this line if you want ot use a GPU (if available)\n",
    "# args.device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "#Use this one to use the CPU\n",
    "args.device = torch.device(\"cpu\")"
   ]
  },
  {
   "source": [
    "Démarrez le Client Ray Serve :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-08 16:13:48,850\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m 2021-03-08 16:13:50,841\tINFO http_state.py:67 -- Starting HTTP proxy with name 'dSsfpl:SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-node:192.168.1.25-0' on node 'node:192.168.1.25-0' listening on '127.0.0.1:8000'\n",
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m INFO:     Started server process [10249]\n"
     ]
    }
   ],
   "source": [
    "client=serve.start()"
   ]
  },
  {
   "source": [
    "On définit ici une classe que l'on va utiliser dans Ray serve. \n",
    "\n",
    "On charge dans l'initilialisation le modèle choisi.\n",
    "\n",
    "La fonction call permet d'utiliser le modèle sur un input et de retourner la réponse du modèle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predict_class:\n",
    "    def __init__(self,args):\n",
    "        self.args=args\n",
    "        self.model=CamembertForSequenceClassification.from_pretrained(\"/home/amaury/Documents/project_a1/camembert-v1\")\n",
    "        self.tokenizer=CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "        trainer=Trainer(\n",
    "            model=self.model\n",
    "        )\n",
    "        self.trainer=trainer\n",
    "        self.model.to(args.device)\n",
    "\n",
    "    def __call__(self,request):\n",
    "        input=await request.body()\n",
    "        text=input.decode(\"utf-8\")\n",
    "        \n",
    "        tokenized=self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        result=self.model(**tokenized)\n",
    "        class_input=np.argmax(result.logits.data.numpy())\n",
    "        return({\"class\":str(class_input)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run those lines in case of changes in the class to be able to create a new backend and endpoint.\n",
    "client.delete_endpoint(\"classpredict\")\n",
    "client.delete_backend(\"classpredict\")"
   ]
  },
  {
   "source": [
    "On crée maintenant l'API proprement dit :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=10247)\u001b[0m 2021-03-08 16:14:14,059\tINFO controller.py:178 -- Registering route '/classpredict' to endpoint 'classpredict' with methods '['GET', 'POST']'.\n"
     ]
    }
   ],
   "source": [
    "# client.create_backend(\"classpredict\", predict_class, args, ray_actor_options={\"num_gpus\": 1})\n",
    "client.create_backend(\"classpredict\", predict_class, args)\n",
    "client.create_endpoint(\"classpredict\",backend=\"classpredict\", route=\"/classpredict\",methods=[\"GET\",\"POST\"])"
   ]
  },
  {
   "source": [
    "Que l'on peut appeler ici : "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[2m\u001b[36m(pid=10249)\u001b[0m 2021-03-08 16:14:29,975\tINFO router.py:248 -- Endpoint classpredict doesn't exist, waiting for registration.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'{\\n  \"class\": \"0\"\\n}'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "payload=\"Bonjour\".encode(\"utf-8\")\n",
    "r=requests.post(\"http://127.0.0.1:8000/classpredict\",data=payload)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}