{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projet Article 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## Creating the training Dataset :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id                                  tweet (without @)  source  Harmful  \\\n",
       "0   1          sale arabe ( arr√™te avec tes hontes toi )     1.0      1.0   \n",
       "1   2  y'a une meuf dans classe elle se pleins du rac...     1.0      1.0   \n",
       "2   3  jparle de qui jveux quand elles se font baiser...     1.0      1.0   \n",
       "3   4        tellement sexy franchement t'ai baisable ^^     0.0      1.0   \n",
       "4   5  Je te prend matin midi et soir biatch comme si...     0.0      1.0   \n",
       "\n",
       "  Looked up word  \n",
       "0          arabe  \n",
       "1         arabes  \n",
       "2         baiser  \n",
       "3       baisable  \n",
       "4         biatch  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>tweet (without @)</th>\n      <th>source</th>\n      <th>Harmful</th>\n      <th>Looked up word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sale arabe ( arr√™te avec tes hontes toi )</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>arabe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>y'a une meuf dans classe elle se pleins du rac...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>arabes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>jparle de qui jveux quand elles se font baiser...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>baiser</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>tellement sexy franchement t'ai baisable ^^</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>baisable</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Je te prend matin midi et soir biatch comme si...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>biatch</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_to_moderate=pd.read_csv(\"selected_tweets.csv\")\n",
    "df_to_moderate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   tweet (without @)  Harmful\n",
       "0          sale arabe ( arr√™te avec tes hontes toi )      1.0\n",
       "1  y'a une meuf dans classe elle se pleins du rac...      1.0\n",
       "2  jparle de qui jveux quand elles se font baiser...      1.0\n",
       "3        tellement sexy franchement t'ai baisable ^^      1.0\n",
       "4  Je te prend matin midi et soir biatch comme si...      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet (without @)</th>\n      <th>Harmful</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sale arabe ( arr√™te avec tes hontes toi )</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>y'a une meuf dans classe elle se pleins du rac...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>jparle de qui jveux quand elles se font baiser...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tellement sexy franchement t'ai baisable ^^</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Je te prend matin midi et soir biatch comme si...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_to_moderate=df_to_moderate.drop([\"Id\",\"source\",\"Looked up word\"],axis=1)\n",
    "df_to_moderate.head()"
   ]
  },
  {
   "source": [
    "df_article1_messages=pd.read_excel(\"AmauryModerationAllMessagesInspireFrom3Aout2020.xlsx\", sheet_name=\"ContenuNormal\")\n",
    "df_article1_messages.head()"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 _id                                            content  \\\n",
       "0  FjuMJ37PjJ7DxqnmT  je te passe mon insta et je te donnerai mon nu...   \n",
       "1  Fo7kokj7nDMKD2JWr  pas de soucis ;) je peux te passer mon Whats'a...   \n",
       "2  B4nkfsKPjNQSR2AZ8  Ah bah je viens de voir que c‚Äôest mal vu de de...   \n",
       "3  irioQAHermketHEb5  Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...   \n",
       "4  ys2Q4j7irtk4S2mYh  Ouii\\nEt du coup toi pour la suite tu vas fair...   \n",
       "\n",
       "              sender       recipients.0           threadId     timestamp  \\\n",
       "0  uoHC9sGdWEkgdazZQ  qHRKFnAqv5ipS9mhR  25woAfTMQDGwuNsoS  1.605613e+12   \n",
       "1  uoHC9sGdWEkgdazZQ  qHRKFnAqv5ipS9mhR  25woAfTMQDGwuNsoS  1.605613e+12   \n",
       "2  qHRKFnAqv5ipS9mhR  uoHC9sGdWEkgdazZQ  25woAfTMQDGwuNsoS  1.605024e+12   \n",
       "3  qHRKFnAqv5ipS9mhR  uoHC9sGdWEkgdazZQ  25woAfTMQDGwuNsoS  1.604848e+12   \n",
       "4  ku5FNNe97ZiNN3mRv  ptBQ9emHw8he5pMNn  2cDBPgc59itjrnGv4  1.600979e+12   \n",
       "\n",
       "   EchantillonNormal  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>content</th>\n      <th>sender</th>\n      <th>recipients.0</th>\n      <th>threadId</th>\n      <th>timestamp</th>\n      <th>EchantillonNormal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FjuMJ37PjJ7DxqnmT</td>\n      <td>je te passe mon insta et je te donnerai mon nu...</td>\n      <td>uoHC9sGdWEkgdazZQ</td>\n      <td>qHRKFnAqv5ipS9mhR</td>\n      <td>25woAfTMQDGwuNsoS</td>\n      <td>1.605613e+12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fo7kokj7nDMKD2JWr</td>\n      <td>pas de soucis ;) je peux te passer mon Whats'a...</td>\n      <td>uoHC9sGdWEkgdazZQ</td>\n      <td>qHRKFnAqv5ipS9mhR</td>\n      <td>25woAfTMQDGwuNsoS</td>\n      <td>1.605613e+12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B4nkfsKPjNQSR2AZ8</td>\n      <td>Ah bah je viens de voir que c‚Äôest mal vu de de...</td>\n      <td>qHRKFnAqv5ipS9mhR</td>\n      <td>uoHC9sGdWEkgdazZQ</td>\n      <td>25woAfTMQDGwuNsoS</td>\n      <td>1.605024e+12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>irioQAHermketHEb5</td>\n      <td>Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...</td>\n      <td>qHRKFnAqv5ipS9mhR</td>\n      <td>uoHC9sGdWEkgdazZQ</td>\n      <td>25woAfTMQDGwuNsoS</td>\n      <td>1.604848e+12</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ys2Q4j7irtk4S2mYh</td>\n      <td>Ouii\\nEt du coup toi pour la suite tu vas fair...</td>\n      <td>ku5FNNe97ZiNN3mRv</td>\n      <td>ptBQ9emHw8he5pMNn</td>\n      <td>2cDBPgc59itjrnGv4</td>\n      <td>1.600979e+12</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_article1_messages=df_article1_messages.drop([\"_id\",\"sender\",\"recipients.0\",\"threadId\",\"timestamp\",\"EchantillonNormal\"], axis=1)\n",
    "df_article1_messages[\"Harmful\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content  Harmful\n",
       "0  je te passe mon insta et je te donnerai mon nu...        0\n",
       "1  pas de soucis ;) je peux te passer mon Whats'a...        0\n",
       "2  Ah bah je viens de voir que c‚Äôest mal vu de de...        0\n",
       "3  Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...        0\n",
       "4  Ouii\\nEt du coup toi pour la suite tu vas fair...        0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>Harmful</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>je te passe mon insta et je te donnerai mon nu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pas de soucis ;) je peux te passer mon Whats'a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ah bah je viens de voir que c‚Äôest mal vu de de...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ouii\\nEt du coup toi pour la suite tu vas fair...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_article1_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Harmful                                            content\n",
       "195      1.0                          nique tes morts sale juif\n",
       "196      1.0  fa√ßon gauchiste c'est comme le chol√©ra √ßa se r...\n",
       "197      1.0          j‚Äôai rien contre lui j‚Äôrigolais mongol va\n",
       "198      1.0            les rebeus la peau lisse c ca faiblesse\n",
       "199      1.0  ce qui tue c'est que meme offset il en marre d..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Harmful</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>1.0</td>\n      <td>nique tes morts sale juif</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>1.0</td>\n      <td>fa√ßon gauchiste c'est comme le chol√©ra √ßa se r...</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>1.0</td>\n      <td>j‚Äôai rien contre lui j‚Äôrigolais mongol va</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>1.0</td>\n      <td>les rebeus la peau lisse c ca faiblesse</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>1.0</td>\n      <td>ce qui tue c'est que meme offset il en marre d...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_to_moderate[\"content\"]=df_to_moderate[\"tweet (without @)\"]\n",
    "df_to_moderate=df_to_moderate.drop([\"tweet (without @)\"], axis=1)\n",
    "df_to_moderate=df_to_moderate.dropna()\n",
    "df_to_moderate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nombre de messages √† mod√©rer 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Nombre de messages √† mod√©rer {df_to_moderate.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_moderate=pd.concat([df_article1_messages[:200],df_to_moderate],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content  Harmful\n",
       "0  je te passe mon insta et je te donnerai mon nu...      0.0\n",
       "1  pas de soucis ;) je peux te passer mon Whats'a...      0.0\n",
       "2  Ah bah je viens de voir que c‚Äôest mal vu de de...      0.0\n",
       "3  Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...      0.0\n",
       "4  Ouii\\nEt du coup toi pour la suite tu vas fair...      0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>Harmful</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>je te passe mon insta et je te donnerai mon nu...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pas de soucis ;) je peux te passer mon Whats'a...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ah bah je viens de voir que c‚Äôest mal vu de de...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Salut üëãüèº ton parcours m‚Äôinspire √©norm√©ment et ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ouii\\nEt du coup toi pour la suite tu vas fair...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_to_moderate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_to_moderate.shape"
   ]
  },
  {
   "source": [
    "## Creating the test Dataset\n",
    "\n",
    "Problem : we do not have a balanced Dataset of real examples from article 1 for which we know the real distribution.\n",
    "\n",
    "Two proposals : \n",
    "Test on ToModerate given by A1, doing a classification by hand --> Too time consuming.\n",
    "\n",
    "Test on the dataset MLMA. \n",
    "See % that come back on Article 1 dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  rt @user personnage ainsi q tte la clique gauc...          1\n",
       "1  @user @user @user bah oui t'as raison l'autre ...          1\n",
       "2  moi j'ai personne √† qui m'adresser pour r√©clam...          1\n",
       "3  @user @user c...est vrai que les anchois sont ...          0\n",
       "4            eh les renois faut se r√©veiller la @url          0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt @user personnage ainsi q tte la clique gauc...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@user @user @user bah oui t'as raison l'autre ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>moi j'ai personne √† qui m'adresser pour r√©clam...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@user @user c...est vrai que les anchois sont ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>eh les renois faut se r√©veiller la @url</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test=pd.read_csv(\"fr_dataset_test.csv\")\n",
    "#Dropping Unused columns\n",
    "cols=[7,8,9]\n",
    "test=test.drop(test.columns[cols],axis=1)\n",
    "test=test.drop(columns=[\"HITId\",\"directness\",\"annotator_sentiment\",\"target\",\"group\"])\n",
    "#Changing sentiment to 0 (for normal) and 1 (for else) \n",
    "test[\"sentiment\"]=[0 if test[\"sentiment\"][x]==\"normal\" else 1 for x in range(test.shape[0])]\n",
    "\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "source": [
    "## Let's go !"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_values=np.array(test[\"tweet\"])\n",
    "test_labels=np.array(test[\"sentiment\"])\n",
    "\n",
    "train_values=np.array(df_to_moderate[\"content\"])\n",
    "train_values=[str(train_values[i]) for i in range(len(train_values))]\n",
    "train_labels=np.array(df_to_moderate[\"Harmful\"])\n",
    "\n",
    "# print([train_values[i] if type(train_values[i])==type(1) else 0 for i in range(len(train_values))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to do 10 times the log reg\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def evaluate_log_reg(train_features, test_features, y_train, y_test):\n",
    "    score=0\n",
    "    for i in range(10):\n",
    "        log_reg=SGDClassifier(loss=\"log\")\n",
    "        log_reg.fit(train_features,y_train)\n",
    "        score+=log_reg.score(test_features,y_test)\n",
    "    score=score/10\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7212159434914227\n"
     ]
    }
   ],
   "source": [
    "# Bag of Word\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow=CountVectorizer()\n",
    "train_bow=bow.fit_transform(train_values)\n",
    "test_bow=bow.transform(test_values)\n",
    "\n",
    "score=evaluate_log_reg(train_bow, test_bow, train_labels, test_labels)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.723864783047427\n"
     ]
    }
   ],
   "source": [
    "# TDIDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tdidf=TfidfVectorizer()\n",
    "train_tdidf=tdidf.fit_transform(train_values)\n",
    "test_tdidf=tdidf.transform(test_values)\n",
    "\n",
    "score=evaluate_log_reg(train_bow, test_bow, train_labels, test_labels)\n",
    "print(score)"
   ]
  },
  {
   "source": [
    "### first attempt with Camembert"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "\n",
    "tokenizer=CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "# cam_mod=CamembertModel.from_pretrained(\"camembert-base\")\n",
    "model=CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=2)\n",
    "\n",
    "num_labels=2\n",
    "\n",
    "# train_cam=cam_tok.encode(train_values)\n",
    "# test_cam=cam_tok.encode(list(test_values), truncation=True)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tokenized=tokenizer(train_values)\n",
    "test_tokenized=tokenizer(test_values.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df=pd.concat([train_tokenized,train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "batch_size=16\n",
    "metric_name=\"accuracy\"\n",
    "args = TrainingArguments(\n",
    "    \"test-glue\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metric(name: \"accuracy\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\nArgs:\n    predictions: Predicted labels, as returned by a model.\n    references: Ground truth labels.\n    normalize: If False, return the number of correctly classified samples.\n        Otherwise, return the fraction of correctly classified samples.\n    sample_weight: Sample weights.\nReturns:\n    accuracy: Accuracy score.\n\"\"\", stored examples: 0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric_accu = load_metric(\"accuracy\")\n",
    "print(metric_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric_accu.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Second attempt with camembert"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember : \n",
    "# test_values=np.array(test[\"tweet\"])\n",
    "# test_labels=np.array(test[\"sentiment\"])\n",
    "\n",
    "# train_values=np.array(df_to_moderate[\"content\"])\n",
    "# train_values=[str(train_values[i]) for i in range(len(train_values))]\n",
    "# train_labels=np.array(df_to_moderate[\"Harmful\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_values, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "tokenizer=CamembertTokenizer.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_values.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class A1Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset =  A1Dataset(train_encodings, train_labels)\n",
    "val_dataset =  A1Dataset(val_encodings, val_labels)\n",
    "test_dataset =  A1Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import CamembertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',          # output directory\n",
    "#     num_train_epochs=3,              # total number of training epochs\n",
    "#     per_device_train_batch_size=16,  # batch size per device during training\n",
    "#     per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "#     weight_decay=0.01,               # strength of weight decay\n",
    "#     logging_dir='./logs',            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    "# )\n",
    "\n",
    "# model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "#     args=training_args,                  # training arguments, defined above\n",
    "#     train_dataset=train_dataset,         # training dataset\n",
    "#     eval_dataset=val_dataset             # evaluation dataset\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import CamembertForSequenceClassification, AdamW\n",
    "\n",
    "device =  torch.device('cpu')\n",
    "\n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert-base')\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7227b8c96b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Essayons celle la\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model(\"Essayons celle la\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38264bitbaseconda67962706fddd4eb99e2936a1eb425e21",
   "language": "python",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}